{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "    \n",
    "api = wandb.Api()\n",
    "project = \"feas-ft\"\n",
    "workspace = \"username\"\n",
    "\n",
    "# Get our two main experiments so far\n",
    "experiment_tags = [\"alpaca\"]\n",
    "\n",
    "# get all runs that both: 1.  match any experiment tag and 2. are finished\n",
    "runs = api.runs(f\"{workspace}/{project}\",\n",
    "                {\"$and\": [\n",
    "                    {\"tags\": {\"$in\": experiment_tags}},\n",
    "                ]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for run in runs:\n",
    "    #print(run.name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiche/miniconda3/envs/bab/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/chiche/miniconda3/envs/bab/lib/python3.10/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import lightning as L\n",
    "from lit_gpt.args import IOArgs\n",
    "from lit_gpt.lora import GPT,  Config\n",
    "from lit_gpt.utils import (\n",
    "    check_valid_checkpoint_dir,\n",
    "    lazy_load,\n",
    ")\n",
    "from finetune.lora import get_longest_seq_length\n",
    "from eval.lm_eval_harness import EvalHarnessBase\n",
    "from pathlib import Path\n",
    "\n",
    "def setup(run, checkpoints =\"checkpoints/meta-llama/Llama-2-7b-hf\",\n",
    "           adapter_path = \"downloads/\", eval_tasks = [\"arc_challenge\", \"piqa\", \"hellaswag\"], num_fewshot=0):\n",
    "    config = run.config\n",
    "    io = IOArgs(\n",
    "        checkpoint_dir=Path(checkpoints),\n",
    "        out_dir=Path(\"out/lora/lima/dloads\"),\n",
    "    )\n",
    "    conf = Config.from_name(\n",
    "            name=io.checkpoint_dir.name,\n",
    "            r=config[\"r\"],\n",
    "            alpha=config[\"alpha\"],\n",
    "            dropout=config[\"dropout\"],\n",
    "            to_query=config[\"to_query\"],\n",
    "            to_key=config[\"to_key\"],\n",
    "            to_value=config[\"to_value\"],\n",
    "            to_projection=config[\"to_projection\"],\n",
    "            to_mlp=config[\"to_mlp\"],\n",
    "            to_head=config[\"to_head\"],\n",
    "        )\n",
    "    fabric = L.Fabric(devices=1, strategy=\"auto\", precision=\"bf16-true\", plugins=None)\n",
    "    fabric.seed_everything(0)  # same seed for every process to init model (FSDP)\n",
    "    \n",
    "    with fabric.init_module(empty_init=(False)):\n",
    "        model = GPT(conf)\n",
    "    #tokenizer = Tokenizer(io.checkpoint_dir)\n",
    "    check_valid_checkpoint_dir(io.checkpoint_dir)\n",
    "\n",
    "    if fabric.global_rank == 0:\n",
    "        os.makedirs(io.out_dir, exist_ok=True)\n",
    "\n",
    "    checkpoint_path = io.checkpoint_dir / \"lit_model.pth\"\n",
    "    #print(adapter_path)\n",
    "    params = {**lazy_load(Path(adapter_path))[\"model\"], **lazy_load(Path(checkpoint_path))}\n",
    "    #print(params.keys())\n",
    "    model.load_state_dict(params, strict=True)\n",
    "    \n",
    "    if len(eval_tasks)> 0:\n",
    "        eval_harness = EvalHarnessBase(\n",
    "            checkpoint_dir=str(io.checkpoint_dir),\n",
    "            model=model,\n",
    "        )\n",
    "\n",
    "    results = eval_harness.run_eval(\n",
    "        eval_tasks=eval_tasks, num_fewshot=num_fewshot,  no_cache=True, bootstrap_iters=10000\n",
    "    )\n",
    "    wandb.init(id=run.id, project=run.project, resume=\"allow\")\n",
    "    wandb.log(results['results'])\n",
    "    wandb.finish()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Run username/feas-ft/rbe30j1e (finished)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Loading model 'checkpoints/meta-llama/Llama-2-7b-hf/lit_model.pth' with {'name': 'Llama-2-7b-hf', 'hf_config': {'org': 'meta-llama', 'name': 'Llama-2-7b-hf'}, 'scale_embeddings': False, 'block_size': 4096, 'vocab_size': 32000, 'padding_multiple': 64, 'padded_vocab_size': 32000, 'n_layer': 32, 'n_head': 32, 'head_size': 128, 'n_embd': 4096, 'rotary_percentage': 1.0, 'parallel_residual': False, 'bias': False, 'lm_head_bias': False, 'n_query_groups': 32, 'shared_attention_norm': False, '_norm_class': 'RMSNorm', 'norm_eps': 1e-05, '_mlp_class': 'LLaMAMLP', 'gelu_approximate': 'none', 'intermediate_size': 11008, 'rope_condense_ratio': 1, 'rope_base': 10000, 'n_expert': 0, 'n_expert_per_token': 0, 'rope_n_elem': 128}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found tasks: ['hellaswag', 'arc_challenge', 'piqa']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiche/miniconda3/envs/bab/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: hellaswag; number of docs: 10042\n",
      "Task: hellaswag; document 0; context prompt (starting on next line):\n",
      "Personal Care and Style: How to increase breast size with a bra. Check your bra size. Wearing a bra that is too big will not make your breasts look larger. That is why it is important to wear the right size bra for you.\n",
      "(end of prompt on previous line)\n",
      "Requests: [Req_loglikelihood('Personal Care and Style: How to increase breast size with a bra. Check your bra size. Wearing a bra that is too big will not make your breasts look larger. That is why it is important to wear the right size bra for you.', ' You can visit a lingerie shop and have them measure you to help you fit a bra to your size, or measure yourself before you shop for a new bra to ensure that you get a good fit. Use a flexible tape measure, like one found in a sewing kit.')[0]\n",
      ", Req_loglikelihood('Personal Care and Style: How to increase breast size with a bra. Check your bra size. Wearing a bra that is too big will not make your breasts look larger. That is why it is important to wear the right size bra for you.', ' This is why it is important to keep your breasts under protection when in the shower and only wear bras that are larger than your breast size. If you are not wearing a bra, try wearing something that is a little bigger.')[0]\n",
      ", Req_loglikelihood('Personal Care and Style: How to increase breast size with a bra. Check your bra size. Wearing a bra that is too big will not make your breasts look larger. That is why it is important to wear the right size bra for you.', ' For a girl, a bra with a support strap will be easier for her, because most women are unable to pull through bra straps and bras that are too small will not be able to support breasts from side-to-side. Many bras have even been created that cover the breast side, and can be sent to other women in the world to make them look bigger.')[0]\n",
      ", Req_loglikelihood('Personal Care and Style: How to increase breast size with a bra. Check your bra size. Wearing a bra that is too big will not make your breasts look larger. That is why it is important to wear the right size bra for you.', ' Choose a color that is flattering to your breast type and specific event, in addition to those that make you uncomfortable. Look for sports bras made from natural material, such as spandex or lycra, as this is a more breathable bra.')[0]\n",
      "]\n",
      "Task: arc_challenge; number of docs: 1172\n",
      "Task: arc_challenge; document 0; context prompt (starting on next line):\n",
      "Question: Cities control the amount of pollution that is allowed to come from cars. How does this most likely help people?\n",
      "Answer:\n",
      "(end of prompt on previous line)\n",
      "Requests: [Req_loglikelihood('Question: Cities control the amount of pollution that is allowed to come from cars. How does this most likely help people?\\nAnswer:', ' The air stays cleaner.')[0]\n",
      ", Req_loglikelihood('Question: Cities control the amount of pollution that is allowed to come from cars. How does this most likely help people?\\nAnswer:', ' Cars can travel at faster speeds.')[0]\n",
      ", Req_loglikelihood('Question: Cities control the amount of pollution that is allowed to come from cars. How does this most likely help people?\\nAnswer:', ' The skills of the drivers improve.')[0]\n",
      ", Req_loglikelihood('Question: Cities control the amount of pollution that is allowed to come from cars. How does this most likely help people?\\nAnswer:', ' It becomes safer to drive on the roads.')[0]\n",
      "]\n",
      "Task: piqa; number of docs: 1838\n",
      "Task: piqa; document 0; context prompt (starting on next line):\n",
      "Question: Remove seeds from  strawberries\n",
      "Answer:\n",
      "(end of prompt on previous line)\n",
      "Requests: [Req_loglikelihood('Question: Remove seeds from  strawberries\\nAnswer:', ' Blend the strawberries, pour the mixture through a fine-mesh strainer with a bowl underneath to catch the pulps and strain out the seeds')[0]\n",
      ", Req_loglikelihood('Question: Remove seeds from  strawberries\\nAnswer:', ' Chop up the strawberries, pour the mixture through a fine-mesh strainer with a bowl underneath to catch the pulps and strain out the seeds')[0]\n",
      "]\n",
      "Running loglikelihood requests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48508/48508 [47:24<00:00, 17.05it/s]\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33musername\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/chiche/feasible-gpt/lit-gpt/wandb/run-20240312_111028-rbe30j1e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/username/feas-ft/runs/rbe30j1e' target=\"_blank\">Alpaca-Llama-ERM</a></strong> to <a href='https://wandb.ai/username/feas-ft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/username/feas-ft' target=\"_blank\">https://wandb.ai/username/feas-ft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/username/feas-ft/runs/rbe30j1e' target=\"_blank\">https://wandb.ai/username/feas-ft/runs/rbe30j1e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/infeasible/avg</td><td>1.00287</td></tr><tr><td>train/infeasible/frac</td><td>0.30465</td></tr><tr><td>train_loss/max</td><td>2.79268</td></tr><tr><td>train_loss/mean</td><td>0.66924</td></tr><tr><td>train_loss/min</td><td>0.03203</td></tr><tr><td>train_loss/running</td><td>0.72889</td></tr><tr><td>train_loss/std</td><td>0.27213</td></tr><tr><td>val_loss/infeasible/frac</td><td>0.5075</td></tr><tr><td>val_loss/infeasible/mean</td><td>0.5075</td></tr><tr><td>val_loss/max</td><td>2.13669</td></tr><tr><td>val_loss/mean</td><td>0.80459</td></tr><tr><td>val_loss/min</td><td>0.16434</td></tr><tr><td>val_loss/std</td><td>0.27307</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Alpaca-Llama-ERM</strong> at: <a href='https://wandb.ai/username/feas-ft/runs/rbe30j1e' target=\"_blank\">https://wandb.ai/username/feas-ft/runs/rbe30j1e</a><br/>Synced 2 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240312_111028-rbe30j1e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Run username/feas-ft/13gehpsw (finished)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 0\n",
      "Loading model 'checkpoints/meta-llama/Llama-2-7b-hf/lit_model.pth' with {'name': 'Llama-2-7b-hf', 'hf_config': {'org': 'meta-llama', 'name': 'Llama-2-7b-hf'}, 'scale_embeddings': False, 'block_size': 4096, 'vocab_size': 32000, 'padding_multiple': 64, 'padded_vocab_size': 32000, 'n_layer': 32, 'n_head': 32, 'head_size': 128, 'n_embd': 4096, 'rotary_percentage': 1.0, 'parallel_residual': False, 'bias': False, 'lm_head_bias': False, 'n_query_groups': 32, 'shared_attention_norm': False, '_norm_class': 'RMSNorm', 'norm_eps': 1e-05, '_mlp_class': 'LLaMAMLP', 'gelu_approximate': 'none', 'intermediate_size': 11008, 'rope_condense_ratio': 1, 'rope_base': 10000, 'n_expert': 0, 'n_expert_per_token': 0, 'rope_n_elem': 128}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found tasks: ['hellaswag', 'arc_challenge', 'piqa']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiche/miniconda3/envs/bab/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: hellaswag; number of docs: 10042\n",
      "Task: hellaswag; document 0; context prompt (starting on next line):\n",
      "Personal Care and Style: How to increase breast size with a bra. Check your bra size. Wearing a bra that is too big will not make your breasts look larger. That is why it is important to wear the right size bra for you.\n",
      "(end of prompt on previous line)\n",
      "Requests: [Req_loglikelihood('Personal Care and Style: How to increase breast size with a bra. Check your bra size. Wearing a bra that is too big will not make your breasts look larger. That is why it is important to wear the right size bra for you.', ' You can visit a lingerie shop and have them measure you to help you fit a bra to your size, or measure yourself before you shop for a new bra to ensure that you get a good fit. Use a flexible tape measure, like one found in a sewing kit.')[0]\n",
      ", Req_loglikelihood('Personal Care and Style: How to increase breast size with a bra. Check your bra size. Wearing a bra that is too big will not make your breasts look larger. That is why it is important to wear the right size bra for you.', ' This is why it is important to keep your breasts under protection when in the shower and only wear bras that are larger than your breast size. If you are not wearing a bra, try wearing something that is a little bigger.')[0]\n",
      ", Req_loglikelihood('Personal Care and Style: How to increase breast size with a bra. Check your bra size. Wearing a bra that is too big will not make your breasts look larger. That is why it is important to wear the right size bra for you.', ' For a girl, a bra with a support strap will be easier for her, because most women are unable to pull through bra straps and bras that are too small will not be able to support breasts from side-to-side. Many bras have even been created that cover the breast side, and can be sent to other women in the world to make them look bigger.')[0]\n",
      ", Req_loglikelihood('Personal Care and Style: How to increase breast size with a bra. Check your bra size. Wearing a bra that is too big will not make your breasts look larger. That is why it is important to wear the right size bra for you.', ' Choose a color that is flattering to your breast type and specific event, in addition to those that make you uncomfortable. Look for sports bras made from natural material, such as spandex or lycra, as this is a more breathable bra.')[0]\n",
      "]\n",
      "Task: arc_challenge; number of docs: 1172\n",
      "Task: arc_challenge; document 0; context prompt (starting on next line):\n",
      "Question: Cities control the amount of pollution that is allowed to come from cars. How does this most likely help people?\n",
      "Answer:\n",
      "(end of prompt on previous line)\n",
      "Requests: [Req_loglikelihood('Question: Cities control the amount of pollution that is allowed to come from cars. How does this most likely help people?\\nAnswer:', ' The air stays cleaner.')[0]\n",
      ", Req_loglikelihood('Question: Cities control the amount of pollution that is allowed to come from cars. How does this most likely help people?\\nAnswer:', ' Cars can travel at faster speeds.')[0]\n",
      ", Req_loglikelihood('Question: Cities control the amount of pollution that is allowed to come from cars. How does this most likely help people?\\nAnswer:', ' The skills of the drivers improve.')[0]\n",
      ", Req_loglikelihood('Question: Cities control the amount of pollution that is allowed to come from cars. How does this most likely help people?\\nAnswer:', ' It becomes safer to drive on the roads.')[0]\n",
      "]\n",
      "Task: piqa; number of docs: 1838\n",
      "Task: piqa; document 0; context prompt (starting on next line):\n",
      "Question: Remove seeds from  strawberries\n",
      "Answer:\n",
      "(end of prompt on previous line)\n",
      "Requests: [Req_loglikelihood('Question: Remove seeds from  strawberries\\nAnswer:', ' Blend the strawberries, pour the mixture through a fine-mesh strainer with a bowl underneath to catch the pulps and strain out the seeds')[0]\n",
      ", Req_loglikelihood('Question: Remove seeds from  strawberries\\nAnswer:', ' Chop up the strawberries, pour the mixture through a fine-mesh strainer with a bowl underneath to catch the pulps and strain out the seeds')[0]\n",
      "]\n",
      "Running loglikelihood requests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48508/48508 [48:21<00:00, 16.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/chiche/feasible-gpt/lit-gpt/wandb/run-20240312_115930-13gehpsw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/username/feas-ft/runs/13gehpsw' target=\"_blank\">Alpaca-Llama-Feas</a></strong> to <a href='https://wandb.ai/username/feas-ft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/username/feas-ft' target=\"_blank\">https://wandb.ai/username/feas-ft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/username/feas-ft/runs/13gehpsw' target=\"_blank\">https://wandb.ai/username/feas-ft/runs/13gehpsw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>multiplier/frac_zeros</td><td>0.53468</td></tr><tr><td>multiplier/max</td><td>17.41353</td></tr><tr><td>multiplier/mean</td><td>0.55879</td></tr><tr><td>multiplier/mean_non_zeros</td><td>1.20087</td></tr><tr><td>multiplier/min</td><td>0</td></tr><tr><td>multiplier/std</td><td>0.9324</td></tr><tr><td>slack/frac_zeros</td><td>0.60546</td></tr><tr><td>slack/max</td><td>1.02763</td></tr><tr><td>slack/mean</td><td>0.02859</td></tr><tr><td>slack/mean_non_zeros</td><td>0.07245</td></tr><tr><td>slack/min</td><td>0</td></tr><tr><td>slack/std</td><td>0.05296</td></tr><tr><td>train/infeasible/avg</td><td>0.93996</td></tr><tr><td>train/infeasible/frac</td><td>0.35097</td></tr><tr><td>train_loss/max</td><td>2.16255</td></tr><tr><td>train_loss/mean</td><td>0.73944</td></tr><tr><td>train_loss/min</td><td>0.03841</td></tr><tr><td>train_loss/running</td><td>0.83782</td></tr><tr><td>train_loss/std</td><td>0.19356</td></tr><tr><td>val_loss/infeasible/frac</td><td>0.4875</td></tr><tr><td>val_loss/infeasible/mean</td><td>0.4875</td></tr><tr><td>val_loss/max</td><td>2.27176</td></tr><tr><td>val_loss/mean</td><td>0.82362</td></tr><tr><td>val_loss/min</td><td>0.23588</td></tr><tr><td>val_loss/std</td><td>0.26983</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Alpaca-Llama-Feas</strong> at: <a href='https://wandb.ai/username/feas-ft/runs/13gehpsw' target=\"_blank\">https://wandb.ai/username/feas-ft/runs/13gehpsw</a><br/>Synced 2 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240312_115930-13gehpsw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for run in runs:\n",
    "    print(run)\n",
    "    weights = run.file(\"out/lora/alpaca/lit_model_lora_finetuned.pth\")\n",
    "    # create the directory if it doesn't exist\n",
    "    os.makedirs(f\"download/{run.id}\", exist_ok=True)\n",
    "    out = weights.download(f\"download/{run.id}\", replace=True)\n",
    "    setup(run, adapter_path=out.name)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
