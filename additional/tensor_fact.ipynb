{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import CP\n",
    "import tntorch as tn\n",
    "\n",
    "from safetensors.torch import load_file as safe_load_file, save_file as safe_save_file\n",
    "\n",
    "adapter_path = \"./dpo_intel/meta-llama/Llama-2-7B-hf_lora_r_8_alpha_16\"\n",
    "\n",
    "# Load state dict\n",
    "state_dict = safe_load_file(f\"{adapter_path}/adapter_model.safetensors\")\n",
    "\n",
    "# Make a copy so we can store CP-decomposed A and B\n",
    "new_state_dict = copy.deepcopy(state_dict)\n",
    "\n",
    "# Parameters\n",
    "d_in = 4096     # Input dimension\n",
    "d_out = 4096    # Output dimension (usually the embedding size)\n",
    "num_layers = 32\n",
    "num_heads = 32\n",
    "d_out_per_head = d_out // num_heads\n",
    "components = ['q_proj', 'v_proj']  # for illustration\n",
    "num_components = len(components)\n",
    "\n",
    "# We will store the \"original\" LoRA expansions for convenience\n",
    "# shape: [d_in, num_layers, num_components, d_out_per_head, num_heads]\n",
    "dWs = torch.zeros(d_in, num_layers, num_components, d_out_per_head, num_heads)\n",
    "\n",
    "# Collect the original LoRA A and B, form the 2D slice, and reshape\n",
    "for layer_idx in range(num_layers):\n",
    "    for comp_idx, comp_name in enumerate(components):\n",
    "        A_key = f\"base_model.model.model.layers.{layer_idx}.self_attn.{comp_name}.lora_A.weight\"\n",
    "        B_key = f\"base_model.model.model.layers.{layer_idx}.self_attn.{comp_name}.lora_B.weight\"\n",
    "\n",
    "        A_orig = state_dict[A_key]  # shape: (rank, d_in)\n",
    "        B_orig = state_dict[B_key]  # shape: (d_out, rank)\n",
    "\n",
    "        # dW_2D = (A^T @ B^T) -> shape (d_in, d_out)\n",
    "        # But the original LORA formulation is often W + B_orig @ A_orig,\n",
    "        # depending on the framework. We'll follow your code convention:\n",
    "        dW_2D = (B_orig @ A_orig).T  # => (d_in, d_out)\n",
    "\n",
    "        # Reshape to (d_in, d_out_per_head, num_heads)\n",
    "        dW_3D = dW_2D.reshape(d_in, d_out_per_head, num_heads)\n",
    "\n",
    "        # Place this slice into dWs\n",
    "        dWs[:, layer_idx, comp_idx, :, :] = dW_3D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposition parameters\n",
    "rank = 8\n",
    "\n",
    "rel_errors = []\n",
    "r2_scores = []\n",
    "\n",
    "##############################################################################\n",
    "# Loop over each layer and each component, perform CP decomposition, \n",
    "# and update new_state_dict with the new A and B.\n",
    "##############################################################################\n",
    "for layer_idx in range(num_layers):\n",
    "    for comp_idx, comp_name in enumerate(components):\n",
    "        # Extract slice for that (layer, component)\n",
    "        data = dWs[:, layer_idx, comp_idx, :, :]  # shape: (d_in, d_out_per_head, num_heads)\n",
    "        tensor = tl.tensor(data)                  # convert to NumPy array internally\n",
    "\n",
    "        # CP decomposition on the 3D slice\n",
    "        cp = CP(rank=rank, verbose=False)\n",
    "        factors = cp.fit_transform(tensor)  # returns (weights, [factor1, factor2, factor3])\n",
    "        weights, (A_factor, B_factor, C_factor) = factors\n",
    "\n",
    "        # By TensorLy convention:\n",
    "        #   A_factor.shape == (d_in, rank)\n",
    "        #   B_factor.shape == (d_out_per_head, rank)\n",
    "        #   C_factor.shape == (num_heads, rank)\n",
    "\n",
    "        # The original LoRA A was shape (rank, d_in). So we transpose A_factor:\n",
    "        A_cp = A_factor.T  # shape: (rank, d_in)\n",
    "\n",
    "        # We want B to be (d_out, rank) = (d_out_per_head * num_heads, rank).\n",
    "        # Combine B_factor and C_factor appropriately:\n",
    "        # Each head's slice is B_factor * diag(C_factor[i]), then we stack them:\n",
    "        B_slices = []\n",
    "        for i in range(num_heads):\n",
    "            # shape is (d_out_per_head, rank) multiplied by diag(...) => (d_out_per_head, rank)\n",
    "            B_slices.append(B_factor @ np.diag(C_factor[i]))\n",
    "        B_cp = np.concatenate(B_slices, axis=0)  # shape: (d_out_per_head * num_heads, rank) = (d_out, rank)\n",
    "\n",
    "        # Compute reconstructed tensor to measure errors\n",
    "        reconstructed = torch.from_numpy(tl.cp_to_tensor(factors))\n",
    "\n",
    "        # Convert data to torch if it isn't already\n",
    "        data_torch = data if isinstance(data, torch.Tensor) else torch.from_numpy(data)\n",
    "        data_torch = data_torch.to(reconstructed.dtype)\n",
    "\n",
    "        # Compute metrics\n",
    "        rel_err = tn.relative_error(data_torch, reconstructed)\n",
    "        r2 = tn.r_squared(data_torch, reconstructed)\n",
    "        rel_errors.append(rel_err)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "        # Now store the new A_cp and B_cp into new_state_dict\n",
    "        # Convert to torch.float32 Tensors\n",
    "        A_torch = torch.from_numpy(A_cp).float()\n",
    "        B_torch = torch.from_numpy(B_cp).float()\n",
    "\n",
    "        # The key names match the original LoRA structure:\n",
    "        A_key = f\"base_model.model.model.layers.{layer_idx}.self_attn.{comp_name}.lora_A.weight\"\n",
    "        B_key = f\"base_model.model.model.layers.{layer_idx}.self_attn.{comp_name}.lora_B.weight\"\n",
    "\n",
    "        # Update them in new_state_dict\n",
    "        new_state_dict[A_key] = A_torch\n",
    "        new_state_dict[B_key] = B_torch\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Save new state_dict to disk (safetensors)\n",
    "##############################################################################\n",
    "output_safetensors_path = f\"{adapter_path}/adapter_model_cp.safetensors\"\n",
    "safe_save_file(new_state_dict, output_safetensors_path)\n",
    "print(f\"New CP-decomposed model saved to: {output_safetensors_path}\")\n",
    "\n",
    "##############################################################################\n",
    "# Dump the error metrics to a file (mean, median, max, std)\n",
    "##############################################################################\n",
    "rel_errors = np.array(rel_errors)\n",
    "r2_scores = np.array(r2_scores)\n",
    "\n",
    "rel_err_mean = rel_errors.mean()\n",
    "rel_err_median = np.median(rel_errors)\n",
    "rel_err_max = rel_errors.max()\n",
    "rel_err_std = rel_errors.std()\n",
    "\n",
    "r2_mean = r2_scores.mean()\n",
    "r2_median = np.median(r2_scores)\n",
    "r2_max = r2_scores.max()\n",
    "r2_std = r2_scores.std()\n",
    "\n",
    "stats_filename = \"cp_decomp_stats.txt\"\n",
    "with open(stats_filename, \"w\") as f:\n",
    "    f.write(\"Relative error stats:\\n\")\n",
    "    f.write(f\"  mean   = {rel_err_mean:.6f}\\n\")\n",
    "    f.write(f\"  median = {rel_err_median:.6f}\\n\")\n",
    "    f.write(f\"  max    = {rel_err_max:.6f}\\n\")\n",
    "    f.write(f\"  std    = {rel_err_std:.6f}\\n\\n\")\n",
    "\n",
    "    f.write(\"R^2 score stats:\\n\")\n",
    "    f.write(f\"  mean   = {r2_mean:.6f}\\n\")\n",
    "    f.write(f\"  median = {r2_median:.6f}\\n\")\n",
    "    f.write(f\"  max    = {r2_max:.6f}\\n\")\n",
    "    f.write(f\"  std    = {r2_std:.6f}\\n\")\n",
    "\n",
    "print(f\"Decomposition stats saved to: {stats_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tntorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
